---
title: "Imputation of incomplete multilevel data"
author: "Hanne Oberman and Gerko Vink"
format:
  html:
    toc: true
---

<!-- This tutorial aims to serve analysts who know their way around multilevel modeling, but are not (as) familiar with missing data imputation. -->

```{r}
library(knitr)
# print everything as kable ----
knit_print.data.frame <- function (x, options, ...) {
  knitr::kable(x) |> knitr::knit_print(options, ...)
}
registerS3method("knit_print", "data.frame", knit_print.data.frame)
options(scipen = 999, digits = 3)
```


# Introduction
This is a tutorial on multiple imputation of incomplete multilevel data with [mice]{.pkg} in [R]{.proglang}. But before we dive into the details and feel sorry for all the holes in our data, it is important to go a few steps back. Because it is not just holes in our data. Most often, there is more data than holes. And more data means more information. In this tutorial we frame your mind to consider the flow of that information in such a way that the multilevel structure is taken into account. In other words, we will show you how to solve for the incomplete data to fit your multilevel model. 

Regardless of the type of model we are estimating, we need information for our model to be fit on. Some information we can see, such as the data we have collected. Other sources of information may be unavailable, such as missing values or cases that are not part of our data set. It can easily occur that the available information is not sufficient for our model to arrive at the correct conclusion. This is a common scenario in practice and extends far beyond the domain of mere missing values in data sets (see e.g. Hand 2020). In any case, when the available information is not sufficient, our standard modeling practices fall short and we need to adjust the model to arrive at the correct conclusion. 

The concept of adjusting models is by itself quite intuitive. When we need to go from data to answer on a dataset that does not tell us everything, there are but three solutions: We can either append the data with the necessary unavailable information, adjust our modeling such that the necessary unavailable information is taken into account, or do both. In either way, some model is needed to solve for the incompleteness. 

Modeling incomplete data sets, however, is not a trivial task. One needs to carefully make assumptions about the nature of the available and unavailable information and explicitly define the models that connect these two information sources. This tasks becomes increasingly challenging when the complexity of the modeling effort increases. For multilevel data sets this is especially the case, because the complexity of modeling can increase exponentially with every additional level. 

In this tutorial we aim to provide a practical guide to imputing incomplete multilevel data. We will use the [R]{.proglang} package [mice]{.pkg} to illustrate the imputation process and demonstrate how it connects to a larger ecosystem of imputation and combination methods for incomplete multilevel data. 

## Intended audience
This tutorial is aimed at researchers and analysts who know their way around multilevel analyses, but lack the skills and expertise of dealing with incomplete sources of information. For them we will gently introduce, explain and demonstrate the necessary methodology and its application in [mice]{.pkg}. For applied researchers and analysts that are both unfamiliar with multilevel modeling and incomplete data analysis, we will try to be as complete as possible, but we may refer to other sources to complement our tutorial. 

# Dealing with unavailable information
First and foremost, the best way to deal with unavailable information is to make sure that you have none. This is in itself impossible to verify, as one would need the potentially unavailable information to definitively prove that there is no deviation from the conclusions obtained on the available information. Since this is impossible to do in practice, it is far more convenient to assume some model that relates the observed and unobserved parts in terms of the problem at hand. For such models, there are generally three scenarios that we need to consider.

## Scenario 1: Missingness is independent of any information
The first scenario is that analysis of the available information by itself yields the correct conclusion. This is an ideal scenario, but it is most likely not the case. Rubin (1987) defines this scenario as **missing completely at random** (MCAR). Hand (2020) defines this - perhaps more intuitively - as *not data dependent*. There is, however, a caveat with us using Hand's terminology, as the term *data dependent* may lull the reader into the false sense of security of assuming that data refers to the available data. While Hand is careful in making this distinction in his book, we would like to explicitly highlight the possibility that more data is always available, and that not considering this data may lead to incorrect conclusions. We therefore favor the explicit use of the term *missingness* in Rubin's terminology and like to stick with Rubin's MCAR in our text. 

With MCAR, the missingness in the data is unrelated to any observed information (i.e. data points), nor to any unobserved information. In terms of classical statistics, this would mean that a random and sufficient sample from a population would be randomly incomplete in such a way that analysis of the complete cases would yield a sufficient statistic. You may recognize this as the age-old adage *"the sample is representative of the population"*, but now the sample is both representative and incomplete. The bottom line is that we can ignore the two missingness mechanisms that are at play here:

1. First, the population has been sampled, meaning that the information that we have obtained is incomplete. Random sampling makes this mechanism ignorable and analyzing a sufficiently large sample will - in the limit - yield the same conclusion as analyzing the population itself. 
2. Second, the sample is now incomplete. This incompleteness is also assumed to be random and thereby ignorable. In other words, we have merely obtained a smaller sample of the information than originally would have been intended. But analyzing this sample, given that it is still sufficiently large, will still yield the same conclusion as analyzing the population. 

In terms of probability we could argue that with MCAR, the probability to be observed is the same for every obtained sequence of information. The complement, however, must also hold: the probability to be unobserved is the same for every unobtained sequence of information. We would like to note that this is a very strong assumption and is often not met in practice. We would also like to note that for structured data this does not mean that every cell has an equal probability to be unobserved. The distribution of random probabilities may change between columns in the data, for example, whilst still being fully random. But as long as this distribution is not related to the sampling, we can still assume that the data is MCAR.

## Scenario 2: Missingness depends on available information
This assumption is violated when the probability of being unobserved - or observed, for that matter - is dependent on more than one dimension in the available information. For example when the probability of being unobserved is dependent on the value of another variable in the data, we have a clear and proven deviation from MCAR. This would bring us to the second scenario: **missing at random (MAR)** (Rubin, 1976). With MAR the observed information holds the key to unlocking the missing information. In Hand's terminology, this would be *seen data dependent*. The difficulty here is that - unlike with MCAR, where the missingness mechanism may not be dependent on any observed nor unobserved data - with MAR, it may only be observed data dependent. 

The observed data dependency of MAR is a very flexible assumption. It allows us to model the unobserved information based on the observed information. In simple terms, if we define a model for all unobserved information, based on all observed information and combine that model with the observed data model, we'd be able to draw correct conclusions. Bayesians would recognize this as a form of conditional probability, where the probability of the unobserved information is conditional on the observed information. Specifying a good prior for the unobserved information is crucial here, as it will determine the outcome of the model. Any sufficient prior will yield a correct posterior predictive distribution and, hence, a correct conclusion. The flexibility in the Bayesian approach is that it allows for straightforward seperation of the missingness and analysis problems for any scenario that is MAR.

## Scenario 3: Missingness may also relate to unavailable information
But what if your missingness is related to the data that you cannot see? This would mean that no matter what type of analysis you perform on the observed information, your conclusions would be invalid. This is the third scenario: **missing not at random (MNAR)** (Rubin, 1976). Hand (2020) defines this as *unseen data dependent*. This is the most difficult scenario to deal with, as it is impossible to model the missing information based on the observed information alone and some form of *adjustment* is needed to arrive at the correct conclusion.

::: {.callout-note}
# Distinguishing beteen missingness mechanisms. 
Everyone who learns about missingness will at some point try to distinguish between the three mechanisms. This is a good exercise, but it is important to note that the distinction is not always clear nor possible. 

Situations in which the missingness mechanism is certain are rare. If you lose one case file during data collection, you can argue that the missingness of that case is random and can therefore be ignored. But how does that relate to other missingness in the data set? Alternatively, for some data collection efforts it is known that the missingness is not ignorable. For example, when collecting blood pressure, there is often a clear reason why such information is (not) collected. The absense of blood pressure measurements may therefore indicate that there is no reason to assume and measure abnormal bloodpressure, increasing the likelihood of MNAR. Solving for missing blood pressure would then too much the observations and could easily lead to biased estimation of the effect. If mechanisms can be deduced from the context of a study, such mechanisms are extremely valuable in solving for the incomplete data.

It becomes problematic when people aim to infer mechanisms from the data itself. Take for example a structured data set. If we determine that the missingness in one column depends on the observed values in another column, we may be tempted to conclude that the missingness is MAR. In our evaluation, however, we did not take into account that the missingness could also relate to itself, or that the missingness could relate to some outside source of the data. In any case, if we would model the missingness, it would not be hard to conceptualize another model that relates to unseen data and would have equal fit to the model that only relates to seen data. This has been clearly demonstrated by (molenberghs 2008). 

Alternatively, we could argue the same for MCAR. The inability to distinguish both MAR and MCAR from MNAR based on the data alone, renders the many MCAR tests that are available in software futile. 
:::

<!-- 1. missing data occur often in data with human subjects -->
<!-- 2. missing data may be resolved, but need to be handled in accordance with the analysis of scientific interest -->
<!-- 3. in human-subjects research, there is often clustering, which may be captured with multilevel modeling techniques -->
<!-- 4. if the analysis of scientific interest is a multilevel model, the missing data handling method should accommodate the multilevel structure of the data -->
<!-- 4. both missingness and multilevel structures require advanced statistical techniques -->
<!-- 5. this tutorial sets out to facilitate empirical researchers in accommodating both multilevel structures as well as missing data -->
<!-- 6. we illustrate the use of the software by means of a case study -->

# Methods

The [`R`]{.proglang} package [`mice`]{.pkg} provides a framework for imputing incomplete data on a variable-by-variable basis. The [`mice`]{.fct} function allows users to flexibly specify how many times and under what model the missing data should be imputed. This is reflected in the first four function arguments

```r
mice(data, m, method, predictorMatrix, ...)
```

where `data` refers to the incomplete dataset, `m` determines the number of imputations, `method` denotes the functional form of the imputation model per variable and `predictorMatrix` specifies the interrelational dependencies between the variables and imputation models (i.e., the set of predictors to be used for imputing each incomplete variable).

The object supplied as `data` should be tabular (e.g. a `data.frame` with $n$ rows and $p$ variables, with missing values coded as `NA`). For multilevel imputation models, a clustering variable is required. The clustering variable should be a factor or an integer vector, with each level representing a unique cluster. Moreover, the data should be in 'long' format, with each row representing a unique unit-level observation. The multilevel imputation functions implemented in `mice` will not work with 'wide' data, where each row represents a cluster and the columns represent the unit-level observations.

The number of imputations `m` should be determined based on the severity of the missing data problem and the intended analysis model of substantive interest. Van Buuren (2018, $\S$ 2.8) suggests using the default `m = 5` for imputation model building, and to increase `m` as required after initial exploration.

The `method` argument specifies the imputation method to be used for each column in data. If not supplied by the user, `method` defaults to convenient standard methods for single level continuous and categorical data. Since these do not take any clustering or multilevel structures into account, valid imputation of incomplete multilevel data will typically require a user-supplied methods vector. The tables 7.2, 7.3 and 7.4 in van Buuren (2018, $\S$ 7.6, $\S$ 7.7 and $\S$ 7.8, respectively) provide an overview of the available methods to perform univariate multilevel imputation. Note that that in the current version of `mice` (v. 3.16) there are no dedicated multilevel imputation methods available for discrete variables with 3 or more unordered categories.

With the `predictorMatix` argument, `mice` users can define which columns should be used as predictors in each imputation model. The default predictor matrix is a square binary matrix with the variables to be imputed in the rows and the imputation model predictors in the columns. The default `predictorMatrix` will not be suitable for multilevel data. Univariate imputation methods for two-level data use other codes than `0` and `1`. In the predictor matrix, `-2` denotes the cluster variable, a value `1` indicates a fixed effect and a value `2` indicates a random effect. An entry of `3` or `4` indicates that the cluster means of the covariates are added as a predictor to the imputation model with fixed or random effects, respectively. 

<!-- Additionally, the method `2l.pan` uses codes `3` and `4` to add class means to codes `1` and `2` respectively. -->

<!-- 2l.bin, 2l.lmer, 2l.norm, 2l.pan, 2lonly.mean, 2lonly.norm and 2lonly.pmm use code -2 to indicate the class variable --> 
<!-- -	2l.bin, 2l.lmer, 2l.norm and 2l.pan use code 2 to indicate the random effects -->
<!-- -	2l.pan uses codes 3 and 4 to add class means to codes 1 and 2 respectively -->

<!-- FIMD, section 7.10 -->

<!-- > Recipe for a level-1 target: -->

<!-- > 1.	Define the most general analytic model to be applied to imputed data; -->
<!-- 2.	Select a 2l method that imputes close to the data; -->
<!-- 3.	Include all level-1 variables; -->
<!-- 4.	Include the disaggregated cluster means of all level-1 variables; -->
<!-- 5.	Include all level-1 interactions implied by the analytic model; -->
<!-- 6.	Include all level-2 predictors; -->
<!-- 7.	Include all level-2 interactions implied by the analytic model; -->
<!-- 8.	Include all cross-level interactions implied by the analytic model; -->
<!-- 9.	Include predictors related to the missingness and the target; -->
<!-- 10.	Exclude any terms involving the target -->

<!-- > Recipe for a level-2 target: -->

<!-- > 1.	Define the most general analytic model to be applied to imputed -->
<!-- data; -->
<!-- 2.	Select a 2lonly method that imputes close to the data; -->
<!-- 3.	Include the cluster means of all level-1 variables; -->
<!-- 4.	Include the cluster means of all level-1 interactions; -->
<!-- 5.	Include all level-2 predictors; -->
<!-- 6.	Include all interactions of level-2 variables; -->
<!-- 7.	Include predictors related to the missingness and the target; -->
<!-- 8.	Exclude any terms involving the target -->

# Case study

Prerequisites: incomplete dataset and known multilevel modeling strategy (i.e. the most general analytic model to be applied to imputed data), plus an assumed missingness mechanism. This tutorial assumes M(C)AR, for MNAR see Munoz et al.

<!-- 1. Load the data, make sure the variables are correctly formatted (e.g. numeric clustering variable) -->
<!-- 2. Explore the missingness -->
<!-- 2. ~~Fix any cluster-level missingness determinately (note that `2l.only` methods do not work if there are inconsistencies, fix those first!). Re-evaluate the missingness~~ -->
<!-- 3. Explore bivariate relations and associations with missingness indicators (optionally test the associations?) -->
<!-- 4. For each incomplete variable: -->
<!--   - Determine the imputation method -->
<!--   - Choose imputation model predictors (see recipe) -->
<!-- 5. Set methods vector and predictor matrix -->
<!-- 6. Impute the incomplete data -->
<!-- 6. If error... -->
<!-- 6. After successful run: -->
<!--   - Evaluate convergence -->
<!--   - Evaluate imputations -->
<!-- 9. Analyze and pool -->
<!-- 9. If error... (e.g. rescale variables by converting imputations to long format, mutate, then back to mids) -->
<!-- 9. After successful run: -->
<!--   - Evaluate missingness ratio's (e.g. fraction of missing information) -->
<!--   - If necessary, increase $m$ and re-impute -->
<!-- 10. For further multilevel model building, AICs could be pooled, how? -->

The most general analytic model to be applied to imputed data (Hox et al, 2018, p. 17, equation 2.12).

\begin{align}
\text{popularity}_{ij} = &\gamma_{00}+ \gamma_{10} \text{gender}_{ij} + \gamma_{20} \text{extraversion}_{ij} + \\
&\gamma_{01} \text{experience}_j + \gamma_{21} \text{extraversion}_{ij} \times \text{experience}_j + \\
&u_{2j} \text{extraversion}_{ij} + u_{0j}+ e_{ij} 
\end{align}

<!-- u_{1j} \text{gender}_{ij} +  -->

Setup `R` environment
```{r, message=FALSE, warning=FALSE}
library(mice)         # for imputation
library(miceadds)     # for imputation
library(ggmice)       # for visualization
library(ggplot2)      # for visualization
library(dplyr)        # for data wrangling
library(lme4)         # for multilevel modeling
library(broom)        # for tidying model output
library(broom.mixed)  # for tidying model output
```

Load the complete data.
```{r}
load("data/popular.RData")
```

Load the incomplete data.
```{r}
load("data/popular_MAR.RData")
dat <- popular_MAR
```


## Comparative truth

Sequentially fit multilevel models to the complete data to obtain the true parameter estimates.

```{r}
mod_true_singlelevel <- lm(popularity_ij ~ 1, data = popular) 
```

```{r}
mod_true_singlelevel |> tidy()
```

```{r}
mod_true_intercept <- lmer(popularity_ij ~ (1 | cluster_id), data = popular, REML = FALSE) 
```

```{r}
mod_true_intercept |> tidy()
```

```{r}
mod_true_predictors <- lmer(popularity_ij ~ gender_ij + extraversion_ij + experience_j + (1 | cluster_id), data = popular, REML = FALSE)
```

```{r}
mod_true_predictors |> tidy()
```


```{r}
mod_true_randomslope <- lmer(popularity_ij ~ gender_ij + extraversion_ij + experience_j + (1  + extraversion_ij | cluster_id), data = popular, REML = FALSE)
```

```{r}
mod_true_randomslope |> tidy()
```

```{r}
mod_true_interaction <- lmer(popularity_ij ~ gender_ij + extraversion_ij + experience_j + extraversion_ij:experience_j + (1  + extraversion_ij | cluster_id), data = popular, REML = FALSE)
```

```{r}
mod_true_interaction |> tidy()
```

## Complete-case analysis

Sequentially fit multilevel models to the incomplete data to obtain the parameter estimates after list-wise deletion.


```{r}
mod_cca_singlelevel <- lm(popularity_ij ~ 1, data = dat) 
```

```{r}
mod_cca_singlelevel |> tidy()
```

```{r}
mod_cca_intercept <- lmer(popularity_ij ~ (1 | cluster_id), data = dat, REML = FALSE) 
```

```{r}
mod_cca_intercept |> tidy()
```

```{r}
mod_cca_predictors <- lmer(popularity_ij ~ gender_ij + extraversion_ij + experience_j + (1 | cluster_id), data = dat, REML = FALSE)
```

```{r}
mod_cca_predictors |> tidy()
```


```{r}
mod_cca_randomslope <- lmer(popularity_ij ~ gender_ij + extraversion_ij + experience_j + (1  + extraversion_ij | cluster_id), data = dat, REML = FALSE)
```

```{r}
mod_cca_randomslope |> tidy()
```

```{r}
mod_cca_interaction <- lmer(popularity_ij ~ gender_ij + extraversion_ij + experience_j + extraversion_ij:experience_j + (1  + extraversion_ij | cluster_id), data = dat, REML = FALSE)
```

```{r}
mod_cca_interaction |> tidy()
```


<!-- 1.	Inspect incomplete data -->
<!-- a.	Explore variables: determine imputation methods with str() and ggmice(),  -->
<!-- b.	If necessary, add variables for polynomial terms -->
<!-- c.	Explore missingness: evaluate missing data patterns with plot_pattern() -->
<!-- d.	Determine imputation model predictors using plot_corr(), plot_flux(), and ggmice() -->
<!-- 2.	Build imputation models -->
<!-- a.	Create methods vector with imputation methods using make.methods() -->
<!-- b.	Create predictor matrix with imputation model predictors using make.predictorMatrix() -->
<!-- c.	Evaluate imputation models using plot_pred() -->
<!-- 3.	Run imputation algorithm -->
<!-- a.	Impute: fill in the missing values with mice() -->
<!-- b.	Inspect convergence: visualize algorithmic convergence with plot_trace() -->
<!-- c.	If necessary, add iterations -->
<!-- 4.	Evaluate imputations -->
<!-- a.	Inspect imputed values: assess imputed values with ggmice(), PPC? -->
<!-- b.	Analyze imputed data: fit the model of scientific interest with lmer()   -->
<!-- c.	Evaluate missingness metrics with testEstimates() -->
<!-- d.	If necessary, add imputations -->
<!-- 5.	Interpret results and report -->

## Inspect incomplete data

### Explore observed data

Assess the structure of the data.
```{r}
str(dat)
```

Print the first few rows of the data.
```{r}
head(dat)
```


### Explore missingness

Inspect the missing data patterns.
```{r}
plot_pattern(dat, square = FALSE)
```

The unit identifier and cluster identifier are observed for all cases. All other variables are incomplete. The outcome variable 'popularity' is missing for `r sum(is.na(dat$popularity_ij))` cases. The cluster-level variable 'teacher experience' is missing only once. The unit-level variables 'gender', 'extraversion' and 'teacher assessment' are missing for `r sum(is.na(dat$gender_ij))`, `r sum(is.na(dat$extraversion_ij))` and `r sum(is.na(dat$assessment_ij))` cases, respectively. 

Teacher assessment is not part of the analysis model, but may serve as auxiliary variable in the imputation models. This is advisable if the observed data in the teacher assessment variable is strongly related to the observed data in the incomplete variables *or* their missingness indicators (see below).  

```{r}
plot_corr(dat, square = FALSE)
```

The auxiliary variable 'teacher assessment' may be useful in the imputation for the incomplete outcome variable 'popularity'. The unit identifier is not relevant, and will be left out of the imputation models.

```{r}
plot_flux(dat) 
```


## Build imputation models

For each incomplete variable we need to define an imputation model: 1) choose the functional form of the imputation model and 2) select the imputation model predictors. 

### Imputation methods

Create the default methods vector, to be filled in with the appropriate imputation methods. 
```{r}
meth <- make.method(dat)
meth
```

The complete identifier variables do not have to be imputed. The default imputation methods for the incomplete variables are not appropriate because of the multilevel structure of the data. We will fill in the methods vector with more appropriate imputation methods, based on the distribution of the incomplete variables. 

#### Popularity

The outcome variable 'popularity' is approximately normally distributed. 

```{r}
ggmice(dat, aes(popularity_ij)) + 
  geom_density()
```

A density plot of the incomplete outcome variable 'popularity' shows that aggregated across clusters, the distribution is approximately normal. Within clusters, there is more variability.

```{r}
ggmice(dat, aes(popularity_ij, group = cluster_id)) +
  geom_density()
```

Further inspect the distribution of the outcome variable in the first few clusters.
```{r}
dat |> 
  filter(cluster_id %in% unique(dat$cluster_id)[1:4]) |>
  ggmice(aes(popularity_ij)) + 
    geom_histogram(fill = "white") +
    facet_wrap(~cluster_id)
```

We will use `2l.norm`: a multilevel method using the linear mixed model with heterogeneous error variances. 

```{r}
meth["popularity_ij"] <- "2l.norm"
```

#### Gender

The unit-level predictor variable 'gender' is dichotomous. 
```{r}
ggmice(dat, aes(as.factor(gender_ij))) + 
  geom_bar(position = "stack", fill = "white")
```

We can use `2l.bin` to impute the missing values. 

```{r}
meth["gender_ij"] <- "2l.bin"
```

#### Extraversion

The unit-level predictor variable 'extraversion' is approximately normally distributed, but not truly continuous. 
```{r}
ggmice(dat, aes(extraversion_ij)) + 
  geom_histogram(fill = "white")
```

We can use `2l.pmm` to impute the missing values. 

```{r}
meth["extraversion_ij"] <- "2l.pmm"
```

#### Teacher assessment

The unit-level auxiliary variable 'teacher assessment' is approximately normally distributed but not continuous either. 

```{r}
ggmice(dat, aes(assessment_ij)) + 
  geom_histogram(fill = "white")
```
We will use `2l.pmm` for this variable too.

```{r}
meth["assessment_ij"] <- "2l.pmm"
```

#### Teacher experience

The cluster-level variable 'teacher experience' is continuous. 

```{r} 
ggmice(dat, aes(experience_j)) + 
  geom_histogram(fill = "white")
```

We can use `2lonly.mean` to impute the missing values if we are sufficiently certain that this variable... Otherwise, `2lonly.pmm` is a good alternative.

```{r}
meth["experience_j"] <- "2lonly.pmm"
```

#### Methods vector

Re-evaluate the methods vector

```{r}
meth
```

All incomplete variables have a multilevel imputation method.


### Imputation model predictors

Imputation model predictors are specified with the `predictorMatrix` argument in `mice`. The default predictor matrix is not appropriate for multilevel imputation models.

```{r}
pred <- make.predictorMatrix(dat)
```

The cluster identifier `cluster_id` will serve as clustering variable for all imputation models, whereas the unit identifier will not be part of any imputation model.

```{r}
pred[, "cluster_id"] <- -2
pred[, "unit_id"] <- 0
```

#### Popularity

For the outcome variable 'popularity', we will include all unit-level variables that appear in the most general analytic model to be applied to imputed data. We will include a fixed effect for 'gender` and a random effect for 'extraversion'. 

```{r}
pred["popularity_ij", "gender_ij"] <- 1
pred["popularity_ij", "extraversion_ij"] <- 2
```

The next step is to include the disaggregated cluster means of all level-1 variables, which means we have to edit the predictor matrix.
```{r}
pred["popularity_ij", "gender_ij"] <- 3
pred["popularity_ij", "extraversion_ij"] <- 4
```

There are no unit-level interactions in the analytic model, so we will continue to the next step: include all level-2 predictors.
```{r}
pred["popularity_ij", "experience_j"] <- 1
```

There are no cluster-level interactions required either, but there is a cross-level interaction implied by the analytic model. We will use passive imputation to impute the interaction effect for extraversion and experience. This is done by adding an empty column to the data for the interaction term and letting `mice` calculate the interaction effect on the fly. 

```{r}
dat$extraversion_experience <- NA
```

We need to edit the methods vector to accommodate this additional variable. Set the imputation method for the interaction term to passive imputation.
```{r}
meth["extraversion_experience"] <- "~ I(extraversion_ij * experience_j)"
```

Add the additional variable to the predictor matrix as well.
```{r}
pred <- rbind(pred, extraversion_experience = 0)
pred <- cbind(pred, extraversion_experience = 0)
```

Further edit the predictor matrix so the interaction term is included in the imputation model for 'popularity'.
```{r}
pred["popularity_ij", "extraversion_experience"] <- 1
```

And finally, include a predictor related to the missingness and the target: the auxiliary variable teacher assessment. 
```{r}
pred["popularity_ij", "assessment_ij"] <- 1
```

The imputation model predictors for popularity now are as follows.
```{r}
pred["popularity_ij", ]
```


#### Gender

The analytic model implies a relation between gender and popularity. So we need to include the outcome variable in the imputation model.

```{r}
pred["gender_ij", "popularity_ij"] <- 1
```


#### Extraversion

The analytic model implies a relation between gender and popularity. So we need to include the outcome variable in the imputation model.

```{r}
pred["extraversion_ij", "popularity_ij"] <- 1
```

#### Experience

The analytic model implies a relation between the cluster-level variable teacher experience and the unit-level variable popularity.

```{r}
pred["experience_j", "popularity_ij"] <- 1
```


#### Teacher assessment

The analytic model does not imply any relation with teacher assessment. This variable is only used as auxiliary variable.
```{r}
pred["assessment_ij", "popularity_ij"] <- 1
```

#### Predictor matrix

Finally, clean up the predictor matrix by setting the diagonal to `0`, to exclude any terms involving the target.
```{r}
diag(pred) <- 0
```

Our final predictor matrix is as follows.
```{r}
pred
```

### Evaluate imputation models

The imputation models can be visualized as follows.
```{r}
plot_pred(pred, meth = meth)
```

## Run imputation algorithm

### Impute

Impute the data using the specified imputation methods and predictor matrix.


```{r, eval=FALSE}
imp <- mice(
  dat, 
  m = 1, 
  method = meth, 
  predictorMatrix = pred,
  maxit = 1)
```


Does not run. Set imputation method for experience to `2lonly.mean` and re-run.
```{r}
meth["experience_j"] <- "2lonly.mean"
imp <- mice(
  dat, 
  method = meth, 
  predictorMatrix = pred,
  maxit = 1,
  printFlag = FALSE)
```

This solves the issue in imputing teacher experience. Now edit the method for gender.
```{r}
meth["gender_ij"] <- "2l.pmm"
imp <- mice(
  dat, 
  method = meth, 
  predictorMatrix = pred,
  maxit = 1,
  printFlag = FALSE)
```

This code runs! Add iterations to reach algorithmic convergence.
```{r}
imp <- mice.mids(imp, maxit = 9, printFlag = FALSE)
```

### Evaluate convergence

Check for algorithmic non-convergence.

```{r}
plot_trace(imp)
```

The trace plots for teacher experience and gender do not exhibit the typical characteristics of convergence: the lines do not intermingle nicely, and thus require further inspection. The traceplot of the interaction term also requires further inspection, as there appears to be some non-stationarity in the standard deviation of the imputations. We will append some extra iterations to evaluate the potential upward trend.

```{r}
imp <- mice.mids(imp, maxit = 10, printFlag = FALSE)
plot_trace(imp)
```

After 20 iterations, there is no apparent trending visible in the trace plots. 

## Evaluate imputations

### Inspect imputed values

We will first evaluate the imputations of the variables with atypical trace plots.

```{r}
ggmice(imp, aes(.imp, experience_j)) + 
  geom_jitter(height = 0)
```

This graphs shows that there is only one imputed value and no variability between the imputations, which explains the atypical trace plots for this variable. 

```{r}
ggmice(imp, aes(.imp, gender_ij)) + 
  geom_jitter(height = 0)
```

Equivalently, for gender, there is no variability in the imputed values. This leaves no more apparent issues with convergence. We can now evaluate the imputations of the other variables. 

#### Popularity

```{r}
ggmice(imp, aes(.imp, popularity_ij)) + 
  geom_jitter(height = 0)
```

There is one imputed value clearly outside of the range of observed values.
```{r}
range(mice::complete(imp)$popularity_ij)
```

If a negative value for popularity is impossible, one might decide to re-impute the data using a different imputation method. For our analyses, a negative value falls outside the range of observations, but does not require re-imputation. 

```{r}
ggmice(imp, aes(popularity_ij, group = .imp)) + 
  geom_density()
```

#### Extraversion

```{r}
ggmice(imp, aes(.imp, extraversion_ij)) + 
  geom_jitter(height = 0)
```

```{r}
ggmice(imp, aes(extraversion_ij, group = .imp)) + 
  geom_density()
```

#### Teacher assessment

```{r}
ggmice(imp, aes(.imp, assessment_ij)) + 
  geom_jitter(height = 0)
```

```{r}
ggmice(imp, aes(assessment_ij, group = .imp)) + 
  geom_density()
```

#### Interaction term

```{r}
ggmice(imp, aes(.imp, extraversion_experience)) + 
  geom_jitter(height = 0)
```

```{r}
ggmice(imp, aes(extraversion_experience, group = .imp)) + 
  geom_density()
```

<!-- # Visualize -->

<!-- ```{r} -->
<!-- ggmice(imp, aes(y = popularity_ij, x = extraversion_ij, group = cluster_id)) + -->
<!--   geom_point(alpha = 0.1) + -->
<!--   geom_smooth(color = "grey", method = "lm", se = FALSE, alpha = 0.1) + -->
<!--   geom_smooth(aes(group = NULL), color = "black", method = "lm", se = FALSE, alpha = 0.1) -->
<!-- ``` -->


### Analyze imputed data

After successful imputation, we can analyze the imputed data and pool the results for further analysis.

#### Single-level model

```{r, echo=TRUE}
mod_cca_singlelevel <- lm(
  popularity_ij ~ 1, 
  data = dat
  )
tidy(cca)
```

```{r, echo=TRUE}
mod_imp_singlelevel <- with(
  imp,
  lm(popularity_ij ~ 1, data = dat)
  ) |> 
  pool()
tidy(fit)
```

#### Intercept-only model
```{r}
cca <- lmer(
  popularity_ij ~ (1 | cluster_id),
  data = dat,
  REML = FALSE
  )
tidy(cca)
```

```{r, echo=TRUE}
fit <- with(
  imp,
  lmer(
    popularity_ij ~ (1 | cluster_id), 
    data = dat, 
    REML = FALSE)
  ) 
pool(fit) |> tidy()
```


```{r, echo=TRUE}
mitml::testEstimates(as.mitml.result(fit), extra.pars = TRUE)
```

#### Model with explanatory variables

```{r}
cca <- lmer(
  popularity_ij ~ gender_ij + extraversion_ij + experience_j + (1 | cluster_id),
  data = dat,
  REML = FALSE
  )
tidy(cca)
```


```{r, echo=TRUE}
fit <- with(
  imp,
  lmer(
    popularity_ij ~ gender_ij + extraversion_ij + experience_j + (1 | cluster_id),
    data = dat, 
    REML = FALSE)
  ) 
pool(fit) |> tidy()
```


```{r, echo=TRUE}
mitml::testEstimates(as.mitml.result(fit), extra.pars = TRUE)
```

#### Model with explanatory variables, extraversion slope random

```{r}
cca <- lmer(
  popularity_ij ~ gender_ij + extraversion_ij + experience_j +
    (1  + extraversion_ij | cluster_id),
  data = dat,
  REML = FALSE
  )
tidy(cca)
```

```{r, echo=TRUE}
fit <- with(
  imp,
  lmer(
    popularity_ij ~ gender_ij + extraversion_ij + experience_j + 
      (1  + extraversion_ij | cluster_id), 
    data = dat, 
    REML = FALSE)
  ) 
pool(fit) |> tidy()
```


```{r, echo=TRUE}
mitml::testEstimates(as.mitml.result(fit), extra.pars = TRUE)
```

#### Model with with cross-level interaction

```{r}
cca <- lmer(
  popularity_ij ~ gender_ij + extraversion_ij + experience_j +
    extraversion_ij:experience_j + (1  + extraversion_ij | cluster_id),
  data = dat,
  REML = FALSE
  )
tidy(cca)
```

```{r, echo=TRUE}
fit <- with(
  imp,
  lmer(
    popularity_ij ~ gender_ij + extraversion_ij + experience_j + 
      extraversion_ij:experience_j + (1  + extraversion_ij | cluster_id),  
    data = dat, 
    REML = FALSE)
  ) 
pool(fit) |> tidy()
```

```{r, echo=TRUE}
mitml::testEstimates(as.mitml.result(fit), extra.pars = TRUE)
```


# References

